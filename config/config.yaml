# DevDebug AI Configuration
# Configuration for all agents and system components

app:
  name: "DevDebug AI"
  version: "1.0.0"
  environment: "development"

api:
  host: "0.0.0.0"
  port: 8000
  cors_origins: "http://localhost:3000,http://localhost:8080"

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/devdebug.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5

# Document Agent Configuration
document_agent:
  doc_dir: "./docs"
  min_word_length: 3
  max_results: 5
  snippet_max_length: 500

# Execution Agent Configuration
execution_agent:
  ssh_enabled: false
  kubeconfig_path: "~/.kube/config"
  timeout: 300
  
  # Security Settings - Granular Control
  read_only_mode: false        # Set to true to only allow safe read operations
  allow_delete: true           # Allow kubectl delete operations
  allow_create: false          # Block kubectl create/apply operations
  allow_update: false          # Block kubectl edit/patch/scale operations
  
  # Forbidden Commands - Always blocked regardless of permissions
  forbidden_commands:
    - "rm -rf"        # Dangerous shell command
    - "destroy"       # Destructive operations
    - "mkfs"          # Filesystem formatting
    - "dd if="        # Low-level disk operations

# LLM Agent Configuration
llm_agent:
  ollama_url: "http://localhost:11434"
  model: "llama3.1:8b"
  temperature: 0.7
  max_tokens: 1000

# Orchestrator Configuration
orchestrator:
  max_session_history: 100
  session_timeout: 3600
  ai_driven_diagnostics: true  # Use LLM to generate diagnostic commands dynamically

# AI-Driven Dynamic Diagnostic Command Generation

## Overview

DevDebug AI now uses **AI to dynamically decide which kubectl commands to run** based on your natural language query, instead of relying on hardcoded templates.

## Problem Solved

### Before (Template-Based):
```
User: "ccr-harbor-jobservice restarted 3 times, what's the cause?"
System: 
  - Checks if "pod" in query ‚Üí runs kubectl get pods ‚úì
  - Checks if "restart" in query ‚Üí No template match ‚úó
  - Misses: kubectl describe, kubectl logs --previous, kubectl get events
Result: Incomplete diagnostics
```

### After (AI-Driven):
```
User: "ccr-harbor-jobservice restarted 3 times, what's the cause?"
LLM: Analyzes query and generates:
  1. kubectl describe pod ccr-harbor-jobservice -n cal-shared-product
  2. kubectl logs ccr-harbor-jobservice -n cal-shared-product --previous
  3. kubectl logs ccr-harbor-jobservice -n cal-shared-product  
  4. kubectl get events -n cal-shared-product --field-selector involvedObject.name=ccr-harbor-jobservice
Result: Complete diagnostics with root cause identified
```

## How It Works

### Architecture

```
User Query
    ‚Üì
üìö Step 1: RAG - Search Documentation
    ‚Üì
ü§ñ Step 2: AI Command Generation
    ‚îú‚îÄ LLM Available? ‚Üí Generate smart commands via Ollama
    ‚îî‚îÄ LLM Unavailable? ‚Üí Use intelligent fallback
    ‚Üì
üîí Step 3: Security Validation
    ‚îú‚îÄ Whitelist check (only get, describe, logs, top allowed)
    ‚îú‚îÄ Blacklist check (block delete, apply, edit, etc.)
    ‚îî‚îÄ Permission check (allow_create, allow_update, allow_delete flags)
    ‚Üì
‚ñ∂Ô∏è  Step 4: Execute Commands
    ‚Üì
ü§ñ Step 5: LLM Analysis
    ‚îî‚îÄ Analyze results and provide root cause + solution
```

### Example Scenarios

#### Scenario 1: Pod Restart Investigation
```yaml
Query: "grafana-operator pod keeps restarting, why?"

AI Generates:
  - kubectl describe pod grafana-operator-xxx -n namespace
  - kubectl logs grafana-operator-xxx -n namespace --previous  # Previous crash logs
  - kubectl logs grafana-operator-xxx -n namespace             # Current logs
  - kubectl get events -n namespace --field-selector involvedObject.name=grafana-operator-xxx

Why Smart: Automatically adds --previous flag for crash logs
```

#### Scenario 2: Resource Listing
```yaml
Query: "describe the pods in nm-cal-observability"

AI Generates:
  - kubectl get pods -n nm-cal-observability              # List first
  - kubectl get pods -n nm-cal-observability -o wide      # Detailed view

Why Smart: Recognizes "describe" intent and lists pods for overview
```

#### Scenario 3: Error Investigation
```yaml
Query: "CreateContainerConfigError in grafana-operator, what's wrong?"

AI Generates:
  - kubectl describe pod grafana-operator-xxx -n namespace  # Get config details
  - kubectl get events -n namespace --sort-by='.lastTimestamp'  # Recent events
  - kubectl logs grafana-operator-xxx -n namespace         # Application logs
  - kubectl get configmaps -n namespace                    # Check config resources

Why Smart: Knows ConfigError needs configmap inspection
```

## Configuration

### Enable/Disable AI-Driven Mode

**config.yaml:**
```yaml
orchestrator:
  ai_driven_diagnostics: true  # Use AI (default)
  # ai_driven_diagnostics: false  # Use templates only
```

### Security Settings

All AI-generated commands go through security validation:

```yaml
execution_agent:
  read_only_mode: true          # Only allow safe read operations (default)
  allow_create: false           # Block kubectl create/apply
  allow_update: false           # Block kubectl edit/patch/scale
  allow_delete: false           # Block kubectl delete
```

## Fallback Behavior

When Ollama LLM is unavailable, the system uses intelligent rule-based fallback:

### Fallback Logic
```python
if "describe" in query:
    if "pod" in query:
        ‚Üí kubectl get pods + kubectl get pods -o wide
    elif "node" in query:
        ‚Üí kubectl describe nodes
    elif "namespace" in query:
        ‚Üí kubectl describe namespace {name}

elif pod_name and "restart|crash|error" in query:
    ‚Üí kubectl describe pod {pod}
    ‚Üí kubectl logs {pod} --previous
    ‚Üí kubectl logs {pod}
    ‚Üí kubectl get events --field-selector involvedObject.name={pod}

elif "namespace" in query:
    ‚Üí kubectl get namespaces

else:
    ‚Üí kubectl get pods -n {namespace} -o wide  # Safe default
```

## Benefits

### For Users
‚úÖ **Natural language** - Ask questions how you naturally think  
‚úÖ **Complete diagnostics** - Gets all relevant info in one go  
‚úÖ **Time saving** - No need to run multiple commands manually  
‚úÖ **Learn as you go** - See which commands the AI chose and why  

### For Developers
‚úÖ **Zero maintenance** - No need to add templates for new scenarios  
‚úÖ **AI adapts** - Handles edge cases automatically  
‚úÖ **Extensible** - Works with any kubectl-compatible cluster  
‚úÖ **Secure by default** - All commands validated  

## Comparison: Template vs AI

| Aspect | Template-Based | AI-Driven |
|--------|---------------|-----------|
| **Flexibility** | Fixed patterns only | Adapts to any query |
| **Maintenance** | Add code for each new case | Zero code changes needed |
| **Coverage** | ~20 predefined scenarios | Unlimited scenarios |
| **Context awareness** | Simple keyword matching | Understands intent |
| **Pod name extraction** | Must be provided explicitly | Extracts from natural language |
| **Command optimization** | May run unnecessary commands | Only runs what's needed |
| **Security** | Template-based validation | Same whitelist + blacklist |

## Real-World Examples

### Example 1: Memory Issue
```
‚ùå Old: "pod using too much memory"
   ‚Üí kubectl get pods
   ‚Üí User has to manually run: kubectl top pods, kubectl describe pod

‚úÖ New: "pod using too much memory"  
   ‚Üí kubectl top pods -n {namespace}
   ‚Üí kubectl describe pod {pod} (if specific pod mentioned)
   ‚Üí kubectl get events (check for OOMKilled)
```

### Example 2: Network Issue
```
‚ùå Old: "service not reachable"
   ‚Üí kubectl get pods (not helpful)
   ‚Üí User manually runs: kubectl get svc, kubectl describe svc

‚úÖ New: "service not reachable"
   ‚Üí kubectl get svc -n {namespace}
   ‚Üí kubectl describe svc {service}
   ‚Üí kubectl get endpoints {service}
   ‚Üí kubectl get pods -l app={selector}
```

### Example 3: Configuration Issue
```
‚ùå Old: "configmap not loading"
   ‚Üí kubectl get pods (shows symptoms, not cause)

‚úÖ New: "configmap not loading"
   ‚Üí kubectl get configmaps -n {namespace}
   ‚Üí kubectl describe configmap {name}
   ‚Üí kubectl get pods -l app={selector}
   ‚Üí kubectl describe pod {pod}
```

## Technical Implementation

### LLM Prompt Template
The AI uses a specialized prompt to generate commands:

```
You are a Kubernetes expert. Based on the user's query, generate
the EXACT kubectl commands needed to gather diagnostic information.

Rules:
1. Only READ-ONLY commands (get, describe, logs, top)
2. Include --previous flag for crash/restart queries
3. Include events for troubleshooting
4. Be specific with pod names
5. Maximum 5 commands

Output: JSON format with {cmd, reason}
```

### Security Pipeline
```python
AI Generated Command
    ‚Üì
Whitelist Check (get, describe, logs, top, etc.)
    ‚Üì
Blacklist Check (delete, apply, edit blocked)
    ‚Üì
Permission Check (read_only_mode, allow_* flags)
    ‚Üì
Execute or Block with helpful message
```

## Future Enhancements

Potential improvements for v2.0:

1. **Multi-round diagnostics** - If initial commands don't reveal issue, AI generates follow-up commands
2. **Cluster-specific learning** - Remember common issues in your cluster
3. **Performance optimization** - Cache similar query patterns
4. **Custom command templates** - Allow users to define their own command patterns
5. **Interactive mode** - Ask clarifying questions before generating commands

## Conclusion

The AI-driven diagnostic system transforms DevDebug from a **template-based tool** into a **truly intelligent assistant** that understands your troubleshooting intent and gathers exactly the information needed - automatically, securely, and efficiently.

**No more guesswork. No more manual command chaining. Just ask, and the AI figures out the rest.** üöÄ
